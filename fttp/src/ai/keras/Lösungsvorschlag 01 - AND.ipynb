{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungsvorschlag 01: AND\n",
    "Wir haben Dir hier eine Lösung für ein neuronales Netz gegeben, das die logische Funktion OR lernt. Erweitere das Netz so, dass es nun ein AND und wenn das geklappt hat, dann noch das XOR lernt. \n",
    "\n",
    "### Hinweise\n",
    "* Sequential, `fit`, `compile`: https://keras.io/models/sequential/\n",
    "* Input Layer: Leider gibt es dazu keine Doku :-) (siehe Folien weiter oben)\n",
    "* Dense Layer: https://keras.io/layers/core/#dense\n",
    "* Loss function: https://keras.io/losses/\n",
    "* Optimizer: https://keras.io/optimizers/\n",
    "* Damit jupyter notebook sich beim Lernen nicht aufhängt, setze den Parameter verbose=0 beim `model.fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiere Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Library, die eine einfache Handhabung \n",
    "# von Vektoren, Matrizen oder generell \n",
    "# großen mehrdimensionalen Arrays ermöglicht.\n",
    "import numpy as np\n",
    "\n",
    "# Keras spezifische Importe\n",
    "from keras.models import Sequential, InputLayer\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras import losses\n",
    "\n",
    "# Library für die Ausgabe von Grafiken\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiere Eingabe und die erwartete Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Daten, die gelernt werden sollen\n",
    "# X = input\n",
    "# Y = output\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([ [0],  [0],  [0],  [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition des Neuronalen Netzes\n",
    "# Sequential ist einfach ein linearer Stapel von Schichten\n",
    "model = Sequential()\n",
    "# Definition des aussehens der Inputdaten. In unserem Fall 2 Neuronen\n",
    "model.add(InputLayer(input_shape=(2,)))\n",
    "# Eine Lage mit genau einem Neuon under sigmoiden Aktivierungsfunction\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zusammenfassung. Wichtig ist vor allem die Anzahl trainierbaren Parameter\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# die Initialen Gewichte sind zufällig\n",
    "print(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfiguriere den Lernalgorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimierung mittels Gradientenabstieg (Lernrate lr=0.3)\n",
    "sgd = SGD(lr=0.3)\n",
    "# Model wird jetzt kompiliert. Wir definieren den Wert, den das Netz optimieren soll. \n",
    "# In diesem Fall ist es der quadratische Abstand zwischen Ausgabedaten (Y) und gelernter Ausgabe \n",
    "model.compile(loss=losses.mean_squared_error, optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lass dein Modell lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fitten wir das Modell. 1000 Iterationen, Keine Textausgabe.\n",
    "history = model.fit(X, Y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Die Ausgaben des Modells für alle 4 Eingaben\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Die Gewichte haben sich geändert\n",
    "print(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ausgabe der \"Geschichte\" des Lernprozesses\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}